{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff34138c-b930-4130-a37c-9500a13f33a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24577 files from dataset.\n",
      "Progress: |██████████████████████████████████████████████████| 100.0%   [24577/24577]\n",
      "Final EMOTION tensor shape: torch.Size([24577, 11008])\n",
      "Final INTENSITY tensor shape: torch.Size([24577, 11008])\n",
      "Wrote numpy arrays to file for training in C:\\Users\\Shark\\Programs\\Uni\\ToneAI\\labs\\DNN\n",
      "Completed preprocessing!\n"
     ]
    }
   ],
   "source": [
    "from progressbar import printProgressBar\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from itertools import cycle\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n",
    "\n",
    "\n",
    "# File Paths\n",
    "\n",
    "# Get the directory of the current script\n",
    "script_dir = os.getcwd()\n",
    "# Other Project Paths\n",
    "root_dir = os.path.join(script_dir, '..', '..')\n",
    "training_data_dir = os.path.join(root_dir, 'training data')\n",
    "categories_dir = os.path.join(training_data_dir, 'categories')\n",
    "cremad_dir = os.path.join(training_data_dir, 'files', 'CREMA-D')\n",
    "emogator_dir = os.path.join(training_data_dir, 'files', 'Emogator', 'data', 'mp3')\n",
    "datasheeet_path = os.path.join(categories_dir, 'data.xlsx')\n",
    "\n",
    "\n",
    "# Read Data\n",
    "audio_files = []\n",
    "data_raw_df = pd.read_excel(datasheeet_path)\n",
    "headers = data_raw_df.columns.values.tolist()\n",
    "data_raw_noheaders_df = data_raw_df.values\n",
    "data_df = pd.DataFrame(data_raw_noheaders_df)\n",
    "\n",
    "# Extract Targets\n",
    "emotion_target_categories = headers[3:11]\n",
    "intensity_target_categories = headers[12:]\n",
    "selected_emotion_targets_df = data_df.iloc[:, [i for i in range(3, 11)]]\n",
    "selected_intensity_targets_df = data_df.iloc[:, [i for i in range(12, 15)]]\n",
    "emotion_targets = selected_emotion_targets_df.to_numpy()\n",
    "intensity_targets = selected_intensity_targets_df.to_numpy()\n",
    "\n",
    "# Load the audio files\n",
    "datasets = data_raw_df['Dataset'].values\n",
    "files = data_raw_df['File'].values\n",
    "num_loaded = 0\n",
    "for dataset, file in zip(datasets, files):\n",
    "    if dataset == 'CREMA-D':\n",
    "        file_path = os.path.join(cremad_dir, file)\n",
    "        audio_files.append(file_path)\n",
    "        num_loaded += 1\n",
    "    elif dataset == 'EmoGator':\n",
    "        file_path = os.path.join(emogator_dir, file)\n",
    "        audio_files.append(file_path)\n",
    "        num_loaded += 1\n",
    "print(f'Loaded {num_loaded} files from dataset.')\n",
    "\n",
    "# Convert audio file to features (log mel spectogram and log mel delta)\n",
    "num_loaded = 0\n",
    "target_frames = 86  # ≈ 2 seconds with librosa defaults (sr=22050, hop_length=512)\n",
    "printProgressBar(0, len(audio_files), prefix='Progress:', suffix='Complete', length=50)\n",
    "emotion_input_features_list = []\n",
    "intensity_input_features_list = []\n",
    "\n",
    "for afile in audio_files:\n",
    "    # Extract y = (the raw data), and sr = (integer value of sample rate)\n",
    "    y, sr = librosa.load(afile)\n",
    "    \n",
    "    # Apply STFT\n",
    "    D = librosa.stft(y)\n",
    "    \n",
    "    # Retreive Mel\n",
    "    S = librosa.feature.melspectrogram(y=y,\n",
    "                                       sr=sr,\n",
    "                                       n_mels=128 * 2,)\n",
    "    S_decible_mel = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    \n",
    "    # Extract Log Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Standardize the length using padding/truncation #? The shape is (n_mels, time_frames) #?\n",
    "    fixed_log_mel = librosa.util.fix_length(log_mel_spectrogram, \n",
    "                                            size=target_frames, \n",
    "                                            axis=1, \n",
    "                                            constant_values=0)\n",
    "    \n",
    "    # Build input for emotion model\n",
    "    emotion_sample_features = fixed_log_mel.flatten(order='C')\n",
    "    emotion_input_features_list.append(emotion_sample_features)\n",
    "\n",
    "    \n",
    "    # Extract Delta Mel spectrogram\n",
    "    delta_log_mel_spectrogram = librosa.feature.delta(log_mel_spectrogram)\n",
    "    \n",
    "    # Standardize the delta spectrogram length too\n",
    "    fixed_delta_log_mel = librosa.util.fix_length(delta_log_mel_spectrogram, \n",
    "                                                  size=target_frames, \n",
    "                                                  axis=1,\n",
    "                                                  constant_values=0)\n",
    "\n",
    "    # Build input for intensity model\n",
    "    intensity_sample_features = fixed_delta_log_mel.flatten(order='C')\n",
    "    intensity_input_features_list.append(intensity_sample_features)\n",
    "    \n",
    "    num_loaded += 1\n",
    "    printProgressBar(\n",
    "        num_loaded,\n",
    "        len(audio_files),\n",
    "        prefix='Progress:',\n",
    "        suffix=f'  [{num_loaded}/{len(audio_files)}]',\n",
    "        length=50\n",
    "    )\n",
    "\n",
    "# Save file to avoid preprocessing more\n",
    "# np.savetxt('input_features.json', input_features, delimiter=',', fmt='%d', comments='')\n",
    "np.savetxt('emotion_targets.csv', emotion_targets, delimiter=',', fmt='%d', comments='')\n",
    "np.savetxt('intensity_targets.csv', intensity_targets, delimiter=',', fmt='%d', comments='')\n",
    "emotion_input_tensor = torch.tensor(np.array(emotion_input_features_list), dtype=torch.double)\n",
    "intensity_input_tensor = torch.tensor(np.array(intensity_input_features_list), dtype=torch.double)\n",
    "print(f\"Final EMOTION tensor shape: {emotion_input_tensor.shape}\")\n",
    "print(f\"Final INTENSITY tensor shape: {intensity_input_tensor.shape}\")\n",
    "print(f'Wrote numpy arrays to file for training in {script_dir}')\n",
    "print('Completed preprocessing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c279355-f89f-4053-b758-2819bbee91b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24577, 11008])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954cfb9e-69e8-4830-a9a3-db320d4fc217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24577, 11008])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensity_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b6d3f6-11cc-43af-8f54-ceea7b43a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(emotion_input_tensor, 'model1_input.pt')\n",
    "torch.save(intensity_input_tensor, 'model2_input.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b952b-e48a-40aa-a7e9-f837c55d749a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
