{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e832640-7eed-4481-8091-be4fc217af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24577 files from dataset.\n"
     ]
    }
   ],
   "source": [
    "from progressbar import printProgressBar\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from itertools import cycle\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n",
    "\n",
    "\n",
    "# File Paths\n",
    "\n",
    "# Get the directory of the current script\n",
    "script_dir = os.getcwd()\n",
    "# Other Project Paths\n",
    "root_dir = os.path.join(script_dir, '..', '..')\n",
    "training_data_dir = os.path.join(root_dir, 'training data')\n",
    "categories_dir = os.path.join(training_data_dir, 'categories')\n",
    "cremad_dir = os.path.join(training_data_dir, 'files', 'CREMA-D')\n",
    "emogator_dir = os.path.join(training_data_dir, 'files', 'Emogator', 'data', 'mp3')\n",
    "datasheeet_path = os.path.join(categories_dir, 'data.xlsx')\n",
    "\n",
    "\n",
    "# Read Data\n",
    "audio_files = []\n",
    "data_raw_df = pd.read_excel(datasheeet_path)\n",
    "headers = data_raw_df.columns.values.tolist()\n",
    "data_raw_noheaders_df = data_raw_df.values\n",
    "data_df = pd.DataFrame(data_raw_noheaders_df)\n",
    "\n",
    "# Extract Targets\n",
    "emotion_target_categories = headers[3:11]\n",
    "intensity_target_categories = headers[12:]\n",
    "selected_emotion_targets_df = data_df.iloc[:, [i for i in range(3, 11)]]\n",
    "selected_intensity_targets_df = data_df.iloc[:, [i for i in range(12, 15)]]\n",
    "emotion_targets = selected_emotion_targets_df.to_numpy()\n",
    "intensity_targets = selected_intensity_targets_df.to_numpy()\n",
    "\n",
    "# Load the audio files\n",
    "datasets = data_raw_df['Dataset'].values\n",
    "files = data_raw_df['File'].values\n",
    "num_loaded = 0\n",
    "for dataset, file in zip(datasets, files):\n",
    "    if dataset == 'CREMA-D':\n",
    "        file_path = os.path.join(cremad_dir, file)\n",
    "        audio_files.append(file_path)\n",
    "        num_loaded += 1\n",
    "    elif dataset == 'EmoGator':\n",
    "        file_path = os.path.join(emogator_dir, file)\n",
    "        audio_files.append(file_path)\n",
    "        num_loaded += 1\n",
    "print(f'Loaded {num_loaded} files from dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85335797-57c7-4a2a-b2e8-67fa83a5339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0%   [24577/24577]\n"
     ]
    }
   ],
   "source": [
    "# Convert audio file to features (log mel spectogram and log mel delta)\n",
    "num_loaded = 0\n",
    "target_frames = 86  # ≈ 2 seconds with librosa defaults (sr=22050, hop_length=512)\n",
    "printProgressBar(0, len(audio_files), prefix='Progress:', suffix='Complete', length=50)\n",
    "input_features = np.empty((len(audio_files), 2), dtype=object)\n",
    "\n",
    "for afile in audio_files:\n",
    "    # Extract y = (the raw data), and sr = (integer value of sample rate)\n",
    "    y, sr = librosa.load(afile)\n",
    "    # Apply STFT\n",
    "    D = librosa.stft(y)\n",
    "    # Retreive Mel\n",
    "    S = librosa.feature.melspectrogram(y=y,\n",
    "                                       sr=sr,\n",
    "                                       n_mels=128 * 2,)\n",
    "    S_decible_mel = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    # Extract Log Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    # Extract Delta Mel spectrogram\n",
    "    delta_log_mel_spectrogram = librosa.feature.delta(log_mel_spectrogram)\n",
    "    input_features[num_loaded, 0] = log_mel_spectrogram\n",
    "    input_features[num_loaded, 1] = delta_log_mel_spectrogram\n",
    "    # sample_features = np.stack([(log_mel_spectrogram.T, delta_log_mel_spectrogram.T)], axis=-1)\n",
    "    # input_features.append(sample_features)\n",
    "    num_loaded += 1\n",
    "    printProgressBar(\n",
    "        num_loaded,\n",
    "        len(audio_files),\n",
    "        prefix='Progress:',\n",
    "        suffix=f'  [{num_loaded}/{len(audio_files)}]',\n",
    "        length=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01607fe7-8db2-475c-901b-b257088f32ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24577, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bc60b0-0117-452a-b49b-1b96714652c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote numpy arrays to file for training in /Users/clinvil/Programs/ToneAI/labs/DNN\n",
      "Completed preprocessing!\n"
     ]
    }
   ],
   "source": [
    "# Save file to avoid preprocessing more\n",
    "# np.savetxt('input_features.json', input_features, delimiter=',', fmt='%d', comments='')\n",
    "np.savetxt('emotion_targets.csv', emotion_targets, delimiter=',', fmt='%d', comments='')\n",
    "np.savetxt('intensity_targets.csv', intensity_targets, delimiter=',', fmt='%d', comments='')\n",
    "np.save('input_features.npy', input_features)\n",
    "print(f'Wrote numpy arrays to file for training in {script_dir}')\n",
    "print('Completed preprocessing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd38df9-884f-428d-9916-274f11567ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[-80.      , -63.645805, -58.657578, ..., -59.13369 , -62.849937,\n",
       "               -68.81144 ],\n",
       "              [-80.      , -62.21421 , -58.048225, ..., -52.6529  , -50.22164 ,\n",
       "               -54.231636],\n",
       "              [-79.7626  , -52.467865, -47.73584 , ..., -44.324654, -41.013523,\n",
       "               -44.056747],\n",
       "              ...,\n",
       "              [-80.      , -80.      , -80.      , ..., -80.      , -80.      ,\n",
       "               -80.      ],\n",
       "              [-80.      , -80.      , -80.      , ..., -80.      , -80.      ,\n",
       "               -80.      ],\n",
       "              [-80.      , -80.      , -80.      , ..., -80.      , -80.      ,\n",
       "               -80.      ]], shape=(128, 99), dtype=float32)                   ,\n",
       "       array([[ 2.1764698e+00,  2.1764698e+00,  2.1764698e+00, ...,\n",
       "               -7.8147256e-01, -7.8147256e-01, -7.8147256e-01],\n",
       "              [ 3.3123832e+00,  3.3123832e+00,  3.3123832e+00, ...,\n",
       "               -2.8086445e-01, -2.8086445e-01, -2.8086445e-01],\n",
       "              [ 3.4211106e+00,  3.4211106e+00,  3.4211106e+00, ...,\n",
       "               -4.6701780e-01, -4.6701780e-01, -4.6701780e-01],\n",
       "              ...,\n",
       "              [ 3.8968581e-15,  3.8968581e-15,  3.8968581e-15, ...,\n",
       "                3.8968581e-15,  3.8968581e-15,  3.8968581e-15],\n",
       "              [ 3.8968581e-15,  3.8968581e-15,  3.8968581e-15, ...,\n",
       "                3.8968581e-15,  3.8968581e-15,  3.8968581e-15],\n",
       "              [ 3.8968581e-15,  3.8968581e-15,  3.8968581e-15, ...,\n",
       "                3.8968581e-15,  3.8968581e-15,  3.8968581e-15]],\n",
       "             shape=(128, 99), dtype=float32)                       ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tone AI",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
